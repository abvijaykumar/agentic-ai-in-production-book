# LLM Provider Configuration
LLM_PROVIDER=openai
OPENAI_API_KEY=your-openai-api-key
ANTHROPIC_API_KEY=your-anthropic-api-key
OPENAI_MODEL=gpt-4
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Database (from v1)
DATABASE_URL=postgresql://supportmax:password@postgres:5432/supportmax
DATABASE_POOL_SIZE=20

# Redis Cluster (NEW in v2)
REDIS_CLUSTER_NODES=redis-0:6379,redis-1:6379,redis-2:6379
REDIS_PASSWORD=your-redis-password
REDIS_MAX_CONNECTIONS=100

# Memory Framework - Mem0 (NEW in v2)
MEM0_API_KEY=your-mem0-api-key
MEM0_ORGANIZATION_ID=your-org-id
MEM0_ENABLED=true

# Neo4j Knowledge Graph (NEW in v2)
NEO4J_URI=neo4j://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-neo4j-password
NEO4J_DATABASE=supportmax

# Vector Database - Pinecone (NEW in v2)
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=supportmax-knowledge
PINECONE_DIMENSION=1536

# Alternative: Weaviate
# WEAVIATE_URL=http://weaviate:8080
# WEAVIATE_API_KEY=your-weaviate-key

# RAG Enhancement - Cohere Rerank (NEW in v2)
COHERE_API_KEY=your-cohere-api-key
COHERE_RERANK_MODEL=rerank-english-v2.0

# Observability - LangSmith (NEW in v2)
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=supportmax-v2
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# LangGraph Configuration (NEW in v2)
LANGGRAPH_CHECKPOINTER=postgres
LANGGRAPH_MAX_ITERATIONS=20
LANGGRAPH_TIMEOUT_SECONDS=300

# CrewAI Configuration (NEW in v2)
CREWAI_PROCESS=sequential
CREWAI_VERBOSE=true
CREWAI_MAX_ITERATIONS=15

# Agent Configuration (NEW in v2)
BILLING_AGENT_MODEL=gpt-4
BILLING_AGENT_TEMPERATURE=0.2
TECHNICAL_AGENT_MODEL=claude-3-sonnet-20240229
TECHNICAL_AGENT_TEMPERATURE=0.3
ACCOUNT_AGENT_MODEL=gpt-4
ACCOUNT_AGENT_TEMPERATURE=0.2

# Memory Configuration (NEW in v2)
EPISODIC_MEMORY_TTL_SECONDS=3600
EPISODIC_MAX_MESSAGES=50
SEMANTIC_SEARCH_TOP_K=20
SEMANTIC_RERANK_TOP_N=5
KNOWLEDGE_GRAPH_MAX_HOPS=2

# Context Management (NEW in v2)
MAX_CONTEXT_TOKENS=8000
CONTEXT_PRUNING_STRATEGY=relevance
CONTEXT_SUMMARIZATION_THRESHOLD=0.7
ENABLE_MULTIMODAL=true

# Application
APP_NAME=SupportMax Pro Cognitive
APP_VERSION=2.0.0
DEBUG=false
LOG_LEVEL=INFO
ENVIRONMENT=production

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
CORS_ORIGINS=*

# Queue (from v1)
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2

# Kubernetes (NEW in v2)
K8S_NAMESPACE=supportmax
K8S_SERVICE_ACCOUNT=supportmax-sa
ENABLE_K8S_INTEGRATION=true

# Monitoring (NEW in v2)
PROMETHEUS_PORT=9090
ENABLE_OPENTELEMETRY=true
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317

# Feature Flags
FEATURE_LANGGRAPH_ORCHESTRATION=true
FEATURE_CREWAI_MULTIAGENT=true
FEATURE_KNOWLEDGE_GRAPH=true
FEATURE_ADVANCED_RAG=true
FEATURE_MEM0_MEMORY=true
FEATURE_LANGSMITH_TRACING=true

# Performance Tuning
MAX_CONCURRENT_WORKFLOWS=100
AGENT_POOL_SIZE=10
MEMORY_CACHE_SIZE_MB=512

# Security
SECRET_KEY=change-in-production
JWT_SECRET=change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=1440